{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick check on language swapping  across Wikipedia editions\n",
    "\n",
    "In this notebook we check users visiting more than one language edition in a given day. \n",
    "Our approach have the following limitations/contrains:\n",
    "\n",
    "* User is approached by concatenating user_agent and IP. \n",
    "* We just consider users visiting Wikipedia (other projects like Wikidata are excluded)\n",
    "* We use the webrequest table, that only contains information from the last 90 days (longitudinal studies would require to track this information along time)\n",
    "* We work on a random sample of users (~10%).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of projects visited by users between Dec 1th and Dec 5th, 2018\n",
    "\n",
    "* Value cnt reflects the % of users visiting that amount of editions. Hence, cnt=1, percent= 94.1, means that the 94.1% of users had just visited one edition, implying that just 5.9% users visted more than one edition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext.sql('use wmf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12847626 users in sample 1 Dec 2018\n",
      "+---+--------------------+\n",
      "|cnt|             percent|\n",
      "+---+--------------------+\n",
      "|  1|   94.83578522600206|\n",
      "|  2|   4.656502298556948|\n",
      "|  3|  0.3842266267713584|\n",
      "|  4| 0.07050329765203314|\n",
      "|  5| 0.02170050715984416|\n",
      "|  6|0.010492210778862959|\n",
      "|  7|0.005448477407421418|\n",
      "|  8|0.003315787679373...|\n",
      "|  9|0.002179390962968567|\n",
      "| 10| 0.00309006504392329|\n",
      "| 11|9.340246984151002E-4|\n",
      "| 12|6.616008280440293E-4|\n",
      "| 13|4.670123492075501E-4|\n",
      "| 14|3.269086444452850...|\n",
      "| 15|2.957744878314484E-4|\n",
      "| 16|2.490732529106934E-4|\n",
      "| 17|2.490732529106934E-4|\n",
      "| 18|2.412897137572342...|\n",
      "| 19|2.023720179899383...|\n",
      "| 20|1.089695481484283...|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "14070336 users in sample 2 Dec 2018\n",
      "+---+--------------------+\n",
      "|cnt|             percent|\n",
      "+---+--------------------+\n",
      "|  1|   94.60975203435085|\n",
      "|  2|   4.866607307743042|\n",
      "|  3|  0.4070549559015506|\n",
      "|  4| 0.07019732862100805|\n",
      "|  5|0.020958987759780577|\n",
      "|  6|0.008834188465719654|\n",
      "|  7| 0.00432825484764543|\n",
      "|  8|0.002494609936820272|\n",
      "|  9|0.001883394966545...|\n",
      "| 10|0.001712823346933...|\n",
      "| 11|8.457509472410609E-4|\n",
      "| 12|5.827863670064454E-4|\n",
      "| 13|3.980004457604992...|\n",
      "| 14|2.985003343203744...|\n",
      "| 15|2.771788818689191...|\n",
      "| 16|1.776787704287943...|\n",
      "| 17|2.274288261488567...|\n",
      "| 18|2.132145245145531...|\n",
      "| 19|1.847859212459461E-4|\n",
      "| 20|1.634644687944907...|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "13962463 users in sample 3 Dec 2018\n",
      "+---+--------------------+\n",
      "|cnt|             percent|\n",
      "+---+--------------------+\n",
      "|  1|   94.34514526555952|\n",
      "|  2|   5.040178083193488|\n",
      "|  3| 0.46078546457025527|\n",
      "|  4|  0.0895687243719106|\n",
      "|  5|0.027889062266449695|\n",
      "|  6|0.012540767341693224|\n",
      "|  7| 0.00678247097234922|\n",
      "|  8|0.004182643133951366|\n",
      "|  9|0.002549693417271...|\n",
      "| 10|0.001962404484079922|\n",
      "| 11|0.001181739926544...|\n",
      "| 12|8.164748583398216E-4|\n",
      "| 13|6.302612941570553E-4|\n",
      "| 14|3.795891885264082...|\n",
      "| 15|4.655339104569158E-4|\n",
      "| 16|4.082374291699108E-4|\n",
      "| 17|3.437788877220301...|\n",
      "| 18| 3.07968586917652E-4|\n",
      "| 19|1.933756243436419...|\n",
      "| 20|2.936444665959007E-4|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "13697850 users in sample 4 Dec 2018\n",
      "+---+--------------------+\n",
      "|cnt|             percent|\n",
      "+---+--------------------+\n",
      "|  1|   94.30589472070434|\n",
      "|  2|   5.073548038560796|\n",
      "|  3|  0.4658760316400019|\n",
      "|  4| 0.08986811798931948|\n",
      "|  5|  0.0283037118963925|\n",
      "|  6|   0.012629719262512|\n",
      "|  7|0.006519271272498969|\n",
      "|  8|0.004139335735170...|\n",
      "|  9|0.002861762977401...|\n",
      "| 10|0.001912708928773...|\n",
      "| 11|0.001379778578390...|\n",
      "| 12|7.957453176958428E-4|\n",
      "| 13|5.840332606941966E-4|\n",
      "| 14|5.986340922115515E-4|\n",
      "| 15|4.453253612793248...|\n",
      "| 16|4.380249455206474E-4|\n",
      "| 17|2.190124727603237E-4|\n",
      "| 18|2.263128885190011...|\n",
      "| 19|1.898108097256138...|\n",
      "| 20|2.263128885190011...|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for day in range(1,5):\n",
    "    ## QUERY FOR A GIVEN DAY. \n",
    "    ## sampling around 10% of users\n",
    "    query = '''\n",
    "    SELECT CONCAT(user_agent,client_ip) as user,   normalized_host.project, COUNT(normalized_host.project) as projectCount\n",
    "    FROM webrequest WHERE normalized_host.project_family = \"wikipedia\" AND is_pageview = 1 AND agent_type=\"user\" \n",
    "    AND year=2018 AND month = 12 and day = %s AND SUBSTR(ip,-1,1) = 5 \n",
    "    GROUP BY user, normalized_host\n",
    "    ''' % str(day)\n",
    "    df = sqlContext.sql(query)\n",
    "    sqlContext.registerDataFrameAsTable(df, \"users\")\n",
    "    dfUsers = sqlContext.sql('SELECT user,COUNT(project) as cnt FROM users GROUP BY user SORT BY cnt')\n",
    "    sqlContext.registerDataFrameAsTable(dfUsers, \"usersCounts\")    \n",
    "    totalUsers = dfUsers.count()\n",
    "    print(totalUsers,'users in sample',day,'Dec 2018')\n",
    "    final = sqlContext.sql('SELECT cnt,100*COUNT(cnt)/%s  as percent FROM usersCounts GROUP BY cnt SORT BY cnt DESC' % totalUsers)\n",
    "    final.sort('cnt').show()\n",
    "    results[country] = final.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is older experiment, spliting users by country. This query was done in May, 2018. \n",
    "`\n",
    "* Date considered is 2018/05/01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FR\n",
      "185887\n",
      "+---+--------------------+\n",
      "|cnt|             percent|\n",
      "+---+--------------------+\n",
      "|  1|   89.62003798006316|\n",
      "|  2|   9.249705466224103|\n",
      "|  3|  0.8510546730002636|\n",
      "|  4| 0.15654671924341132|\n",
      "|  5|0.042498937526561836|\n",
      "|  6|0.024208255553104845|\n",
      "|  7|0.013449030862836024|\n",
      "|  8|0.009683302221241937|\n",
      "|  9|0.005379612345134...|\n",
      "| 10|0.001613883703540323|\n",
      "| 11|0.001613883703540323|\n",
      "| 12|0.003227767407080646|\n",
      "| 13|0.001075922469026882|\n",
      "| 14|0.002151844938053764|\n",
      "| 16|0.001613883703540323|\n",
      "| 17| 5.37961234513441E-4|\n",
      "| 18|0.001075922469026882|\n",
      "| 19| 5.37961234513441E-4|\n",
      "| 24| 5.37961234513441E-4|\n",
      "| 27|0.001613883703540323|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "DZ\n",
      "10634\n",
      "+---+--------------------+\n",
      "|cnt|             percent|\n",
      "+---+--------------------+\n",
      "|  1|   87.78446492382923|\n",
      "|  2|  10.334775249200677|\n",
      "|  3|  1.6174534511942824|\n",
      "|  4| 0.21628738010156104|\n",
      "|  5|0.018807598269700958|\n",
      "|  6|0.009403799134850479|\n",
      "| 14|0.009403799134850479|\n",
      "| 94|0.009403799134850479|\n",
      "+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import LongType\n",
    "\n",
    "def hashing(a):\n",
    "    return hash(a)\n",
    "\n",
    "results = {}\n",
    "sqlContext.udf.register(\"hashingPy\", hashing, LongType())\n",
    "for country in ['FR','DZ']:\n",
    "    print(country)\n",
    "    ## QUERY FOR A GIVEN DAY (2018/05/01). \n",
    "    query = '''\n",
    "    SELECT hashingPy(CONCAT(user_agent,client_ip)) as user,   normalized_host.project, COUNT(normalized_host) as projectCount\n",
    "    FROM webrequest WHERE normalized_host.project_class = \"wikipedia\" AND is_pageview = 1 AND agent_type=\"user\" \n",
    "    AND year=2018 AND month = 5 and day = 10 AND SUBSTR(ip,-1,1) = 5 AND geocoded_data.country_code = \"%s\" AND access_method = \"desktop\"\n",
    "    GROUP BY user, normalized_host\n",
    "    ''' % country\n",
    "    df = sqlContext.sql(query)\n",
    "    sqlContext.registerDataFrameAsTable(df, \"users\")\n",
    "    dfUsers = sqlContext.sql('SELECT user,COUNT(project) as cnt FROM users GROUP BY user SORT BY cnt')\n",
    "    sqlContext.registerDataFrameAsTable(dfUsers, \"usersCounts\")    \n",
    "    totalUsers = dfUsers.count()\n",
    "    print(totalUsers)\n",
    "    final = sqlContext.sql('SELECT cnt,100*COUNT(cnt)/%s  as percent FROM usersCounts GROUP BY cnt SORT BY cnt DESC' % totalUsers)\n",
    "    final.sort('cnt').show()\n",
    "    results[country] = final.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3602264\n",
      "+---+--------------------+\n",
      "|cnt|             percent|\n",
      "+---+--------------------+\n",
      "|  1|   91.09659924980512|\n",
      "|  2|   7.741492572448882|\n",
      "|  3|   0.827701689826176|\n",
      "|  4| 0.17502881521176683|\n",
      "|  5| 0.06484810663516055|\n",
      "|  6| 0.02970354199470111|\n",
      "|  7| 0.01676723305121446|\n",
      "|  8|0.009799392826289244|\n",
      "|  9|0.007717368854698...|\n",
      "| 10|0.006051749677425086|\n",
      "| 11|0.003830924107727...|\n",
      "| 12|0.002748271642500...|\n",
      "| 13|0.001998743012727...|\n",
      "| 14|0.001276974702575...|\n",
      "| 15|9.160905475001277E-4|\n",
      "| 16|7.495286297728317E-4|\n",
      "| 17|6.662476709091838E-4|\n",
      "| 18|3.886444746970239E-4|\n",
      "| 19|6.940079905303997E-4|\n",
      "| 20|4.719254335606718...|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#for all countries\n",
    "from pyspark.sql.types import LongType\n",
    "\n",
    "def hashing(a):\n",
    "    return hash(a)\n",
    "\n",
    "results = {}\n",
    "sqlContext.udf.register(\"hashingPy\", hashing, LongType())\n",
    "for country in ['BE']:\n",
    "    ## QUERY FOR A GIVEN DAY (2018/05/01). The information for the same days of the survey is not currently available\n",
    "    ## sampling 10% of users\n",
    "    query = '''\n",
    "    SELECT hashingPy(CONCAT(user_agent,client_ip)) as user,   normalized_host.project, COUNT(normalized_host) as projectCount\n",
    "    FROM webrequest WHERE normalized_host.project_class = \"wikipedia\" AND is_pageview = 1 AND agent_type=\"user\" \n",
    "    AND year=2018 AND month = 12 and day = 14 AND SUBSTR(ip,-1,1) = 5 AND access_method = \"desktop\"\n",
    "    GROUP BY user, normalized_host\n",
    "    ''' \n",
    "    df = sqlContext.sql(query)\n",
    "    sqlContext.registerDataFrameAsTable(df, \"users\")\n",
    "    dfUsers = sqlContext.sql('SELECT user,COUNT(project) as cnt FROM users GROUP BY user SORT BY cnt')\n",
    "    sqlContext.registerDataFrameAsTable(dfUsers, \"usersCounts\")    \n",
    "    totalUsers = dfUsers.count()\n",
    "    print(totalUsers)\n",
    "    final = sqlContext.sql('SELECT cnt,100*COUNT(cnt)/%s  as percent FROM usersCounts GROUP BY cnt SORT BY cnt DESC' % totalUsers)\n",
    "    final.sort('cnt').show()\n",
    "    results[country] = final.toPandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark - YARN",
   "language": "python",
   "name": "spark_yarn_pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
